<div align="center">

# <img width="24" height="24" alt="shopping-cart" src="https://github.com/user-attachments/assets/1da27076-6bda-418c-a54c-52d1f14578a2"/> Ecommerce con DataBricks
### Proyecto de ETL con Databricks - Medallion Architecture <img width="24" height="24" alt="medallion" src="https://github.com/user-attachments/assets/9a4ec107-285b-42d4-a095-9a16d7b2c783" />

[![Databricks](https://img.shields.io/badge/Databricks-FF3621?style=for-the-badge&logo=databricks&logoColor=white)](https://databricks.com/)
[![Azure](https://img.shields.io/badge/Azure-0078D4?style=for-the-badge&logo=microsoft-azure&logoColor=white)](https://azure.microsoft.com/)
[![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=for-the-badge&logo=apache-spark&logoColor=white)](https://spark.apache.org/)
[![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=for-the-badge&logo=delta&logoColor=white)](https://delta.io/)
[![CI/CD](https://img.shields.io/badge/CI%2FCD-GitHub_Actions-2088FF?style=for-the-badge&logo=github-actions&logoColor=white)](https://github.com/features/actions)



</div>

## ğŸ“– DescripciÃ³n del Proyecto
Este proyecto implementa un pipeline ETL completo utilizando la Arquitectura Medallion (Bronze â†’ Silver â†’ Gold) en Databricks con Unity Catalog. El objetivo es procesar y analizar datos de e-commerce brasileÃ±o para generar insights de negocio mediante dashboards interactivos.

## ğŸ¯ Objetivos

- âœ… Implementar arquitectura Medallion en Databricks
- âœ… Procesar datos de e-commerce con PySpark
- âœ… Crear mÃ©tricas de negocio accionables
- âœ… Desarrollar dashboards interactivos
- âœ… Aplicar mejores prÃ¡cticas de ingenierÃ­a de datos

## ğŸ† CaracterÃ­sticas Principales

- Ingesta automatizada desde Azure Storage usando Managed Identity
- Transformaciones complejas con PySpark (window functions, agregaciones, joins)
- Calidad de datos con validaciones y limpieza
- Seguridad mediante permisos granulares en Unity Catalog

## ğŸ—ï¸ Arquitectura
### Arquitectura Medallion
<img width="914" height="566" alt="image" src="https://github.com/user-attachments/assets/9bf04084-6002-4a64-a23f-9ac1f51edfc4" />

## ğŸ“Š Datasets
Brazilian E-Commerce Public Dataset by Olist

- Fuente: Kaggle
- PerÃ­odo: 2016-2018
- Registros: ~100,000 Ã³rdenes
- Formato: 6 archivos CSV

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n
### Prerrequisitos

âœ… Cuenta de Azure con suscripciÃ³n activa
âœ… Databricks Workspace configurado
âœ… Unity Catalog habilitado
âœ… Azure Storage Account (Data Lake Gen2)
âœ… Managed Identity configurada

## ğŸ“ Estructura del Proyecto
```
proyecto-etl-ecommerce/
â”‚
â”œâ”€â”€ README.md                          # âœ… Este archivo - DocumentaciÃ³n principal
â”œâ”€â”€ .gitignore                         # Archivos ignorados por Git
â”‚
â”œâ”€â”€ .github/                           # GitHub Actions (CI/CD)
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ deploy.yaml                # Pipeline de deployment
â”‚
â”œâ”€â”€ datasets/                          # ğŸ“‚ Datasets descargados
â”‚   â”œâ”€â”€ olist_orders_dataset.csv
â”‚   â”œâ”€â”€ olist_order_items_dataset.csv
â”‚   â”œâ”€â”€ olist_customers_dataset.csv
â”‚   â”œâ”€â”€ olist_products_dataset.csv
â”‚   â”œâ”€â”€ olist_order_payments_dataset.csv
â”‚   â”œâ”€â”€ olist_geolocation_dataset.csv
â”‚   â””â”€â”€ product_category_name_translation.csv
â”‚
â”œâ”€â”€ dashboard/                         # âœ… Dashboards y Apps
â”‚   â”œâ”€â”€ Delivery_metricas.pdf                
â”‚   â”œâ”€â”€ Metrics Ventas Category.pdf    # ConfiguraciÃ³n de Databricks App
â”‚   â””â”€â”€ Metrics ventas mensual.pdf     # SQL queries para dashboards
â”‚
â”œâ”€â”€ reversion/                         # âœ… Scripts de revocaciÃ³n
â”‚   â””â”€â”€ revoke_permissions             # REVOKE statements para seguridad
â”‚
â”œâ”€â”€ proceso/                           # âœ… Scripts ETL en PySpark
â”‚   â”œâ”€â”€ Ingest_customers.py            # Ingesta de customers
â”‚   â”œâ”€â”€ Ingest_location.py             # ingesta de location
â”‚   â”œâ”€â”€ ingest_order_items.py          # ingesta de order items
â”‚   â”œâ”€â”€ Ingest_Orders.py               # Ingesta de ordenes
â”‚   â”œâ”€â”€ ingest_payments.py             # ingesta de payments
â”‚   â””â”€â”€ ingest_product_categories.py   # ingesta de categoria de productos
â”‚   â”œâ”€â”€ ingest_productos.py            # Ingesta de productos
â”‚   â”œâ”€â”€ Transform_customers.py         # Transformaciones de customers
â”‚   â”œâ”€â”€ Transform_order_items.py       # Transformaciones de order items
â”‚   â”œâ”€â”€ Transform_orders.py            # Transformaciones de ordenes
â”‚   â”œâ”€â”€ Transform_payments.py          # Transformaciones de payments
â”‚   â”œâ”€â”€ Transform_products.py          # Transformaciones de productos
â”‚   â”œâ”€â”€ Load_delivery_metrics.py       # Cargar metricas delivery
â”‚   â”œâ”€â”€ Load_ventas_categoria.py       # Cargar metricas de ventas de categoria
â”‚   â””â”€â”€ Load_ventas_mensuales.py       # Cargar metricas de ventas mensuales
â”‚
â”œâ”€â”€ scripts/                           # âœ… Scripts de preparaciÃ³n de ambiente
â”‚   â”œâ”€â”€ preparacion_de_ambiente        # Preparar ambiente
â”‚
â”œâ”€â”€ seguridad/                         # âœ… Scripts de seguridad
â”‚   â”œâ”€â”€ Permissions                    # GRANT statements por rol
â”‚
â””â”€â”€ certificaciones/                   # âœ… Certificaciones databricks
    â”œâ”€â”€ certificacion1.png             
    â”œâ”€â”€ certificacion2.png             
```

## ğŸ› ï¸ TecnologÃ­as

<div align="center">

| TecnologÃ­a | PropÃ³sito |
|:----------:|:----------|
| ![Databricks](https://img.shields.io/badge/Azure_Databricks-FF3621?style=flat-square&logo=databricks&logoColor=white) | Motor de procesamiento distribuido Spark |
| ![Delta Lake](https://img.shields.io/badge/Delta_Lake-00ADD8?style=flat-square&logo=delta&logoColor=white) | Storage layer con ACID transactions |
| ![PySpark](https://img.shields.io/badge/PySpark-E25A1C?style=flat-square&logo=apache-spark&logoColor=white) | Framework de transformaciÃ³n de datos |
| ![ADLS](https://img.shields.io/badge/ADLS_Gen2-0078D4?style=flat-square&logo=microsoft-azure&logoColor=white) | Data Lake para almacenamiento persistente |
| ![GitHub Actions](https://img.shields.io/badge/GitHub_Actions-2088FF?style=flat-square&logo=github-actions&logoColor=white) | AutomatizaciÃ³n CI/CD |
| ![Databricks](https://img.shields.io/badge/Azure_Databricks-FF3621?style=flat-square&logo=databricks&logoColor=white) | DataBricks Dashboards |  VisualizaciÃ³n |

</div>


---

## âš™ï¸ Requisitos Previos

- â˜ï¸ Cuenta de Azure con acceso a Databricks
- ğŸ’» Workspace de Databricks configurado
- ğŸ–¥ï¸ Cluster activo (nombre: `cluster_SD`)
- ğŸ™ Cuenta de GitHub con permisos de administrador
- ğŸ“¦ Azure Data Lake Storage Gen2 configurado

---

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1ï¸âƒ£ Clonar el Repositorio

```bash
git clone https://github.com/Euly02/EcommerceDataBricks.git
```

### 2ï¸âƒ£ Configurar Databricks Token

1. Ir a Databricks Workspace
2. **User Settings** â†’ **Developer** â†’ **Access Tokens**
3. Click en **Generate New Token**
4. Configurar:
   - **Comment**: `GitHub CI/CD`
   - **Lifetime**: `90 days`
5. âš ï¸ Copiar y guardar el token

### 3ï¸âƒ£ Configurar GitHub Secrets

En tu repositorio: **Settings** â†’ **Secrets and variables** â†’ **Actions**

| Secret Name | Valor Ejemplo |
|------------|---------------|
| `DATABRICKS_HOST` | `https://adb-xxxxx.azuredatabricks.net` |
| `DATABRICKS_TOKEN` | `dapi_xxxxxxxxxxxxxxxx` |

### 4ï¸âƒ£ Verificar Storage Configuration

```python
storage_path = "abfss://raw@adlsprojectsmartdata.dfs.core.windows.net"
```

<div align="center">

âœ… **Â¡ConfiguraciÃ³n completa!**

</div>

---

## ğŸ’» Uso

### ğŸ”„ Despliegue AutomÃ¡tico (Recomendado)

```bash
git add .
git commit -m " feat: mejoras"
git push origin master
```

**GitHub Actions ejecutarÃ¡**:
- ğŸ“¤ Deploy de notebooks a `/etl/scripts`
- ğŸ”§ CreaciÃ³n del workflow `WF_ECOMMERCE`
- â–¶ï¸ EjecuciÃ³n completa:  Bronze â†’ Silver â†’ Gold
- ğŸ“§ Notificaciones de resultados

### ğŸ–±ï¸ Despliegue Manual desde GitHub

1. Ir al tab **Actions** en GitHub
2. Seleccionar **Deploy ETL**
3. Click en **Run workflow**
4. Seleccionar rama `main`
5. Click en **Run workflow**

#
<div align="center">

**Proyecto**: Data Engineering - Arquitectura Medallion  
**TecnologÃ­a**: Azure Databricks + Delta Lake + CI/CD  
**Ãšltima actualizaciÃ³n**: 2026


</div>
